<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../img/favicon.ico">

    
    <title>Documentation - regenie</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../css/base.min.css" rel="stylesheet">
    <link href="../css/cinder.min.css" rel="stylesheet">

    
    <link href="../custom/style.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-166859683-2', 'auto');
    ga('send', 'pageview');
    </script>
    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="..">regenie</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="..">Home</a>
                    </li>
                
                
                
                    <li >
                        <a href="../overview/">Overview</a>
                    </li>
                
                
                
                    <li >
                        <a href="../install/">Install</a>
                    </li>
                
                
                
                    <li class="active">
                        <a href="./">Documentation</a>
                    </li>
                
                
                
                    <li >
                        <a href="../performance/">Performance</a>
                    </li>
                
                
                
                    <li >
                        <a href="../recommendations/">UKBB Analysis</a>
                    </li>
                
                
                
                    <li >
                        <a href="../faq/">F.A.Q.</a>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../install/">
                            <i class="fas fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="next" href="../performance/">
                            Next <i class="fas fa-arrow-right"></i>
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#getting-started">Getting started</a></li>
        <li class="first-level "><a href="#basic-options">Basic options</a></li>
            <li class="second-level"><a href="#input">Input</a></li>
                
                <li class="third-level"><a href="#genetic-data-file-format">Genetic data file format</a></li>
                <li class="third-level"><a href="#covariate-file-format">Covariate file format</a></li>
                <li class="third-level"><a href="#phenotype-file-format">Phenotype file format</a></li>
                <li class="third-level"><a href="#predictions-file-format">Predictions file format</a></li>
            <li class="second-level"><a href="#options">Options</a></li>
                
            <li class="second-level"><a href="#output">Output</a></li>
                
        <li class="first-level "><a href="#gene-based-testing">Gene-based testing</a></li>
            <li class="second-level"><a href="#input_1">Input</a></li>
                
                <li class="third-level"><a href="#annotation-input-files">Annotation input files</a></li>
                <li class="third-level"><a href="#mask-definitions">Mask definitions</a></li>
                <li class="third-level"><a href="#skatacat-tests">SKAT/ACAT tests</a></li>
                <li class="third-level"><a href="#joint-test-for-burden-masks">Joint test for burden masks</a></li>
                <li class="third-level"><a href="#lovolodo-schemes">LOVO/LODO schemes</a></li>
                <li class="third-level"><a href="#writing-mask-files">Writing mask files</a></li>
            <li class="second-level"><a href="#options_1">Options</a></li>
                
            <li class="second-level"><a href="#output_1">Output</a></li>
                
            <li class="second-level"><a href="#example-run">Example run</a></li>
                
            <li class="second-level"><a href="#checking-input-files">Checking input files</a></li>
                
        <li class="first-level "><a href="#interaction-testing">Interaction testing</a></li>
            <li class="second-level"><a href="#options_2">Options</a></li>
                
            <li class="second-level"><a href="#output_2">Output</a></li>
                
        <li class="first-level "><a href="#conditional-analyses">Conditional analyses</a></li>
        <li class="first-level "><a href="#ld-computation">LD computation</a></li>
            <li class="second-level"><a href="#output_3">Output</a></li>
                
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h2 id="getting-started">Getting started</h2>
<p>To run <strong>regenie</strong>, use the command <code>./regenie</code> on the command line,
followed by options and flags as needed.</p>
<p>To get a full list of options use</p>
<pre><code>./regenie --help
</code></pre>
<p>The directory <code>examples/</code> contains some small example files that are
useful when getting started. A test run on a set of binary traits can be achieved by the
following 2 commands.</p>
<p>In <strong>Step 1</strong>, the whole genome regression model is fit to the traits, and
a set of genomic predictions are produced as output</p>
<pre><code>./regenie \
  --step 1 \
  --bed example/example \
  --exclude example/snplist_rm.txt \
  --covarFile example/covariates.txt \
  --phenoFile example/phenotype_bin.txt \
  --remove example/fid_iid_to_remove.txt \
  --bsize 100 \
  --bt --lowmem \
  --lowmem-prefix tmp_rg \
  --out fit_bin_out
</code></pre>
<p>In <strong>Step 2</strong>, a set of imputed SNPs are tested for association using a
Firth logistic regression model</p>
<pre><code>./regenie \
  --step 2 \
  --bgen example/example.bgen \
  --covarFile example/covariates.txt \
  --phenoFile example/phenotype_bin.txt \
  --remove example/fid_iid_to_remove.txt \
  --bsize 200 \
  --bt \
  --firth --approx \
  --pThresh 0.01 \
  --pred fit_bin_out_pred.list \
  --out test_bin_out_firth
</code></pre>
<p>One of the output files from these two commands is included in <code>example/test_bin_out_firth_Y1.regenie</code>.</p>
<h2 id="basic-options">Basic options</h2>
<h3 id="input">Input</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Argument</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--bgen, --bed, --pgen</code></td>
<td>FILE</td>
<td>Required</td>
<td>Input genetic data file. Either BGEN file eg. <code>file.bgen</code>, or bed/bim/fam prefix that assumes<code>file.bed</code>, <code>file.bim</code>, <code>file.fam</code> exist, or pgen/pvar/psam prefix that assumes<code>file.pgen</code>, <code>file.pvar</code>, <code>file.psam</code> exist</td>
</tr>
<tr>
<td><code>--sample</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Sample file corresponding to input BGEN file</td>
</tr>
<tr>
<td><code>--bgi</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Index bgi file corresponding to input BGEN file</td>
</tr>
<tr>
<td><code>--ref-first</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>Specify to use the first allele as the reference allele for BGEN or PLINK bed/bim/fam file input [default is to use the last allele as the reference]</td>
</tr>
<tr>
<td><code>--keep</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Inclusion file that lists individuals to retain in the analysis</td>
</tr>
<tr>
<td><code>--remove</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Exclusion file that lists individuals to remove from the analysis</td>
</tr>
<tr>
<td><code>--extract</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Inclusion file that lists IDs of variants to keep</td>
</tr>
<tr>
<td><code>--exclude</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Exclusion file that lists IDs of variants to remove</td>
</tr>
<tr>
<td><code>--extract-or</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Inclusion file that lists IDs of variants to keep regardless of minimum MAC filter</td>
</tr>
<tr>
<td><code>--exclude-or</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Exclusion file that lists IDs of variants to remove unless MAC is above threshold</td>
</tr>
<tr>
<td><code>--phenoFile</code></td>
<td>FILE</td>
<td>Required</td>
<td>Phenotypes file</td>
</tr>
<tr>
<td><code>--phenoCol</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Use for each phenotype you want to include in the analysis</td>
</tr>
<tr>
<td><code>--phenoColList</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Comma separated list of phenotypes to include in the analysis</td>
</tr>
<tr>
<td><code>--phenoExcludeList</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Comma separated list of phenotypes to ignore from the analysis</td>
</tr>
<tr>
<td><code>--covarFile</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Covariates file</td>
</tr>
<tr>
<td><code>--covarCol</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Use for each covariate you want to include in the analysis</td>
</tr>
<tr>
<td><code>--covarColList</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Comma separated list of covariates to include in the analysis</td>
</tr>
<tr>
<td><code>--catCovarList</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Comma separated list of categorical covariates to include in the analysis</td>
</tr>
<tr>
<td><code>--covarExcludeList</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Comma separated list of covariates to ignore</td>
</tr>
<tr>
<td><code>--pred</code></td>
<td>FILE</td>
<td>Optional</td>
<td>File containing predictions from Step 1 (see Overview). <strong>This is required for <code>--step 2</code></strong></td>
</tr>
<tr>
<td><code>--tpheno-file</code></td>
<td>STRING</td>
<td>Optional</td>
<td>to use a phenotype file in transposed format (e.g. BED format)</td>
</tr>
<tr>
<td><code>--tpheno-indexCol</code></td>
<td>INT</td>
<td>Optional</td>
<td>index of phenotype name column in transposed phenotype file</td>
</tr>
<tr>
<td><code>--tpheno-ignoreCols</code></td>
<td>INT</td>
<td>Optional</td>
<td>indexes of columns to ignore in transposed phenotype file</td>
</tr>
<tr>
<td><code>--iid-only</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to specify if header in transposed phenotype file only contains sample IID (assume FID=IID)</td>
</tr>
</tbody>
</table>
<p>Note: Parameter expansion can be used when specifying phenotypes/covariates (e.g. <code>--covarCol PC{1:10}</code>).
Also, multiple files can be specified for <code>--extract/--exclude/--keep/--remove</code> by using a comma-separated list.</p>
<h4 id="genetic-data-file-format">Genetic data file format</h4>
<p><strong>regenie</strong> can read BGEN files, bed/bim/fam files or pgen/psam/pvar 
files in Step 1 and Step 2.</p>
<p>The BGEN file format is described
<a href="https://www.well.ox.ac.uk/~gav/bgen_format/">here</a>.</p>
<p>The bed/bim/fam file format is described <a href="https://www.cog-genomics.org/plink/1.9/formats">here</a>.</p>
<p>The pgen/pvar/psam file format is described <a href="https://www.cog-genomics.org/plink/2.0/formats#pgen">here</a>.</p>
<p>Tools useful for genetic data file format conversion are : <a href="http://www.cog-genomics.org/plink/">PLINK</a>, <a href="https://www.well.ox.ac.uk/~gav/qctool/">QCTOOL</a>, <a href="https://samtools.github.io/bcftools/">BCFTOOLS</a>.</p>
<p>Step 2 of <strong>regenie</strong> can be sped up by using BGEN files using v1.2 format with 8 bits encoding 
(genotype file can be generated with <a href="https://www.cog-genomics.org/plink/2.0/">PLINK2</a> using 
option <code>--export bgen-1.2 'bits=8'</code>) as well as having an accompanying .bgi index file 
(a useful tool to create such file is bgenix which is part of the BGEN library).</p>
<p>To include X chromosome genotypes in step 1 and/or step 2, males should be coded as diploid 
so that their genotypes are 0/2 (this is done automatically for BED and PGEN file formats with haploid genotypes).
Chromosome values of 23 (for human analyses), X, Y, XY, PAR1 and PAR2 are all acceptable and 
will be collapsed into a single chromosome.</p>
<h5 id="sample-inclusionexclusion-file-format">Sample inclusion/exclusion file format</h5>
<pre><code>2 2 
7 7 
.
</code></pre>
<p>No header. Each line starts with individual FID IID. Space/tab separated.</p>
<p>Samples listed in the file that are not in bgen/bed/pgen file are ignored.</p>
<h5 id="variant-inclusionexclusion-file-format">Variant inclusion/exclusion file format</h5>
<pre><code>20
31
.
</code></pre>
<p>No header. Each line must start with variant ID 
(if there are additional columns, file must be space/tab separated).</p>
<p>Variants listed in this file that are not in bgen/bed/pgen file are ignored.</p>
<h4 id="covariate-file-format">Covariate file format</h4>
<pre><code>FID IID V1 V2 V3
1 1 1.46837294454993 1.93779743016325 0.152887004505393
2 2 -1.2234390803815 -1.63408619199948 -0.190201446835255
3 3 0.0711531925667286 0.0863906292357564 0.14254739715665
.
</code></pre>
<p>Line 1 : Header with FID, IID and <script type="math/tex">C</script> covariate names.</p>
<p>Followed by lines of <script type="math/tex">C+2</script> values. Space/tab separated.</p>
<p>Each line contains individual FID and IID followed by <script type="math/tex">C</script> covariate
values.</p>
<p>Samples listed in this file that are not in bgen/bed/pgen file are ignored.
Genotyped samples that are not in this file are removed from the analysis as well as
samples with missing values at any of the covariates included.</p>
<p>If <code>--step 2</code> is specified, then the covariate file should be the same
as that used in Step 1.</p>
<h4 id="phenotype-file-format">Phenotype file format</h4>
<pre><code>FID IID Y1 Y2
1 1 1.64818554321186 2.2765234736685
2 2 -2.67352013711554 -1.53680421614647
3 3 0.217542851471485 0.437289912695016
.
</code></pre>
<p>Line 1 : Header with FID, IID and <script type="math/tex">P</script> phenotypes names.</p>
<p>Followed by lines of <script type="math/tex">P+2</script> values. Space/tab separated. 
Each line contains individual FID and IID followed by P phenotype values
(for binary traits, must be coded as 0=control, 1=case, NA=missing unless using <code>--1</code>).</p>
<p>Samples listed in this file that are not in bgen/bed/pgen file are ignored.
Genotyped samples that are not in this file are removed from the analysis.</p>
<p>Missing values must be coded as NA.</p>
<p>With QTs, missing values are mean-imputed in Step 1 and they are dropped when testing each phenotype in Step 2 (unless using <code>--force-impute</code>).</p>
<p>With BTs, missing values are mean-imputed in Step 1 when fitting the
level 0 linear ridge regression and 
they are dropped when fitting the level 1 logistic ridge regression for each trait . 
In Step 2, missing values are dropped when testing each trait.</p>
<p>To remove all samples that have missing values at <strong>any</strong> of the <script type="math/tex">P</script> phenotypes, use option <code>--strict</code> in Step 1 and 2.</p>
<p>If using the transposed phenotype file format with option <code>--tpheno-file</code>, 
the header line must contain subject IDs as "FID_IID",
otherwise use option <code>--iid-only</code> and only include IIDs (so will assume FID=IID).</p>
<h4 id="predictions-file-format">Predictions file format</h4>
<p>Running <code>--step 1 --out foo</code> will produce</p>
<ol>
<li>A set of files containing genomic predictions for each phenotype
   from Step 1 (see Output section below).</li>
<li>A file called <code>foo_pred.list</code> listing the locations of the prediction files.</li>
</ol>
<p>The file list is needed as an input file when using <code>--step 2</code>
via the <code>--pred</code> option. 
It has one line per phenotype (in any order) that specifies the name of the phenotype and its
corresponding prediction file name. 
Each phenotype must have exactly one prediction file and phenotype names 
must match with those in the phenotype file.
Phenotypes in this file not included in the analysis are ignored.</p>
<p>Each prediction file contains the genetic predictions for the phenotype (space separated).</p>
<p>Line 1 starts with 'FID_IID' followed by $N$ sample identifiers.
It is followed by 23 lines containing the genetic predictions for each chromosome 
(sex chromosomes are collapsed into chromosome 23).</p>
<p>More specifically, each line has $N+1$ values which are the chromosome number followed by the $N$
leave-one chromosome out (LOCO) predictions for each individual.</p>
<p>Samples in this file not in the bed/pgen/bgen input file are ignored. Genotyped samples not 
present in this file will be ignored in the analysis of the corresponding trait. </p>
<p>Samples with missing LOCO predictions must have their corresponding phenotype value set to missing.</p>
<h3 id="options">Options</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Argument</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--step</code></td>
<td>INT</td>
<td>Required</td>
<td>specify step for the regenie run (see Overview) [argument can be <code>1</code> or <code>2</code>]</td>
</tr>
<tr>
<td><code>--qt</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>specify that traits are quantitative (this is the default so can be ommitted)</td>
</tr>
<tr>
<td><code>--bt</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>specify that traits are binary with 0=control,1=case,NA=missing</td>
</tr>
<tr>
<td><code>-1,--cc12</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>specify to use 1/2/NA encoding for binary traits (1=control,2=case,NA=missing)</td>
</tr>
<tr>
<td><code>--bsize</code></td>
<td>INT</td>
<td>Required</td>
<td>size of the genotype blocks</td>
</tr>
<tr>
<td><code>--cv</code></td>
<td>INT</td>
<td>Optional</td>
<td>number of cross validation (CV) folds [default is 5]</td>
</tr>
<tr>
<td><code>--loocv</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to use leave-one out cross validation</td>
</tr>
<tr>
<td><code>--lowmem</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to reduce memory usage by writing level 0 predictions to disk (details below). This is very useful if the number of traits is large (e.g. greater than 10)</td>
</tr>
<tr>
<td><code>--lowmem-prefix</code></td>
<td>FILE PREFIX</td>
<td>Optional</td>
<td>prefix where to temporarily write the level 0 predictions</td>
</tr>
<tr>
<td><code>--split-l0</code></td>
<td>PREFIX,N</td>
<td>Optional</td>
<td>split level 0 across N jobs and set prefix of output files of level 0 predictions</td>
</tr>
<tr>
<td><code>--run-l0</code></td>
<td>FILE,K</td>
<td>Optional</td>
<td>run level 0 for job K in {1..N} specifying the master file created from '--split-l0'</td>
</tr>
<tr>
<td><code>--run-l1</code></td>
<td>FILE</td>
<td>Optional</td>
<td>run level 1 specifying the master file from '--split-l0'</td>
</tr>
<tr>
<td><code>--l1-phenoList</code></td>
<td>STRING</td>
<td>Optional</td>
<td>to specify a subset of phenotypes to analyze when using <code>--run-l1</code></td>
</tr>
<tr>
<td><code>--keep-l0</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>avoid deleting the level 0 predictions written on disk after fitting the level 1 models</td>
</tr>
<tr>
<td><code>--print-prs</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to print whole genome predictions (i.e. PRS) without using LOCO scheme</td>
</tr>
<tr>
<td><code>--force-step1</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to run step 1 when &gt;1M variants are used (not recommened)</td>
</tr>
<tr>
<td><code>--minCaseCount</code></td>
<td>INT</td>
<td>Optional</td>
<td>flag to ignore BTs with low case counts [default is 10]</td>
</tr>
<tr>
<td><code>--apply-rint</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to apply Rank Inverse Normal Transformation (RINT) to quantitative phenotypes (use in both Step 1 &amp; 2)</td>
</tr>
<tr>
<td><code>--nb</code></td>
<td>INT</td>
<td>Optional</td>
<td>number of blocks (determined from block size if not provided)</td>
</tr>
<tr>
<td><code>--strict</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to removing samples with missing data at any of the phenotypes</td>
</tr>
<tr>
<td><code>--ignore-pred</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>skip reading the file specified by <code>--pred</code> (corresponds to simple linear/logistic regression)</td>
</tr>
<tr>
<td><code>--use-relative-path</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to use relative paths instead of absolute ones for the step 1 output pred.list file</td>
</tr>
<tr>
<td><code>--use-prs</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to use whole genome PRS in <code>--pred</code> (this is output in step 1 when using <code>--print-prs</code>)</td>
</tr>
<tr>
<td><code>--gz</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to output files in compressed gzip format (LOCO prediction files in step 1 and association results files in step 2) <strong>[this only works when compiling with Boost Iostream library (see Install tab)]</strong>.</td>
</tr>
<tr>
<td><code>--force-impute</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to keep and impute missing observations for QTs in step 2</td>
</tr>
<tr>
<td><code>--write-samples</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to write sample IDs for those kept in the analysis for each trait in step 2</td>
</tr>
<tr>
<td><code>--print-pheno</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to write phenotype name in the first line of the sample ID files when using <code>--write-samples</code></td>
</tr>
<tr>
<td><code>--firth</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>specify to use Firth likelihood ratio test (LRT) as fallback for p-values less than threshold</td>
</tr>
<tr>
<td><code>--approx</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to use approximate Firth LRT for computational speedup (only works when option <code>--firth</code> is used)</td>
</tr>
<tr>
<td><code>--firth-se</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to compute SE based on effect size and LRT p-value when using Firth correction (instead of based on Hessian of unpenalized log-likelihood)</td>
</tr>
<tr>
<td><code>--write-null-firth</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to write the null estimates for approximate Firth [can be used in step 1 or 2]</td>
</tr>
<tr>
<td><code>--compute-all</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to write the null Firth estimates for all chromosomes (regardless of the genotype file)</td>
</tr>
<tr>
<td><code>--use-null-firth</code></td>
<td>FILE</td>
<td>Optional</td>
<td>to use stored null estimates for approximate Firth in step 2</td>
</tr>
<tr>
<td><code>--spa</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>specify to use Saddlepoint approximation as fallback for p-values less than threshold</td>
</tr>
<tr>
<td><code>--pThresh</code></td>
<td>FLOAT</td>
<td>Optional</td>
<td>P-value threshold below which to apply Firth/SPA correction [default is 0.05]</td>
</tr>
<tr>
<td><code>--test</code></td>
<td>STRING</td>
<td>Optional</td>
<td>specify to carry out dominant or recessive test [default is additive; argument can be <code>dominant</code> or <code>recessive</code>]</td>
</tr>
<tr>
<td><code>--chr</code></td>
<td>INT</td>
<td>Optional</td>
<td>specify which chromosomes to test in step 2 (use for each chromosome to include)</td>
</tr>
<tr>
<td><code>--chrList</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Comma separated list of chromosomes to test in step 2</td>
</tr>
<tr>
<td><code>--range</code></td>
<td>STRING</td>
<td>Optional</td>
<td>specify chromosome region for variants to test in step 2 [format=CHR:MINPOS-MAXPOS]</td>
</tr>
<tr>
<td><code>--minMAC</code></td>
<td>FLOAT</td>
<td>Optional</td>
<td>flag to specify the minimum minor allele count (MAC) when testing variants [default is 5]. Variants with lower MAC are ignored.</td>
</tr>
<tr>
<td><code>--minINFO</code></td>
<td>FLOAT</td>
<td>Optional</td>
<td>flag to specify the minimum imputation info score (IMPUTE/MACH R^2) when testing variants. Variants with lower info score are ignored.</td>
</tr>
<tr>
<td><code>--sex-specific</code></td>
<td>STRING</td>
<td>Optional</td>
<td>to perform sex-specific analyses [either 'male'/'female']</td>
</tr>
<tr>
<td><code>--af-cc</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to output A1FREQ in case/controls separately in the step 2 result file</td>
</tr>
<tr>
<td><code>--no-split</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>flag to have summary statistics for all traits output in the same file</td>
</tr>
<tr>
<td><code>--starting-block</code></td>
<td>INT</td>
<td>Optional</td>
<td>to start step 2 at a specific block/set number (useful if program crashes during a job)</td>
</tr>
<tr>
<td><code>--nauto</code></td>
<td>INT</td>
<td>Optional</td>
<td>number of autosomal chromosomes (for non-human studies) [default is 22]</td>
</tr>
<tr>
<td><code>--maxCatLevels</code></td>
<td>INT</td>
<td>Optional</td>
<td>maximum number of levels for categorical covariates (for non-human studies) [default is 10]</td>
</tr>
<tr>
<td><code>--niter</code></td>
<td>INT</td>
<td>Optional</td>
<td>maximum number of iterations for logistic regression [default is 30]</td>
</tr>
<tr>
<td><code>--maxstep-null</code></td>
<td>INT</td>
<td>Optional</td>
<td>maximum step size for logistic model with Firth penalty under the null [default is 25]</td>
</tr>
<tr>
<td><code>--maxiter-null</code></td>
<td>INT</td>
<td>Optional</td>
<td>maximum number of iterations for logistic model with Firth penalty under the null [default is 1000]</td>
</tr>
<tr>
<td><code>--par-region</code></td>
<td>STRING</td>
<td>Optional</td>
<td>specify build code to determine bounds for PAR1/PAR2 regions (can be 'b36/b37/b38/hg18/hg19/hg38' or 'start,end' bp bounds of non-PAR region) [default is hg38]</td>
</tr>
<tr>
<td><code>--force-qt</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>force QT run for binary traits</td>
</tr>
<tr>
<td><code>--threads</code></td>
<td>INT</td>
<td>Optional</td>
<td>number of computational threads to use [default=all-1]</td>
</tr>
<tr>
<td><code>--debug</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>debug flag (for use by developers)</td>
</tr>
<tr>
<td><code>--verbose</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>verbose screen output</td>
</tr>
<tr>
<td><code>--version</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>print version number and exit</td>
</tr>
<tr>
<td><code>--help</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>Prints usage and options list to screen</td>
</tr>
</tbody>
</table>
<p>When step 1 of <strong>regenie</strong> is run in low memory mode (i.e. using <code>--lowmem</code>), 
temporary files are created on disk (using <code>--lowmem-prefix tmp_prefix</code> determines 
where the files are written [as in <code>tmp_prefix_l0_Y1</code>,...,<code>tmp_prefix_l0_YP</code> 
for P phenotypes]). If the prefix is not specified, the default is to use the 
prefix specified by <code>--out</code> (see below).
These are automatically deleted at the end of the program (unless the run
was not successful in which case the user would need to delete the files)</p>
<p>See the <a href="https://github.com/rgcgithub/regenie/wiki/Further-parallelization-for-level-0-models-in-Step-1">Wiki page</a> for more details on how to run the level 0 models for Step 1 
of <strong>regenie</strong> in parallel.</p>
<h3 id="output">Output</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Argument</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--out</code></td>
<td>FILE PREFIX</td>
<td>Required</td>
<td>Output files that depends on <code>--step</code></td>
</tr>
</tbody>
</table>
<p>A log file <code>file.log</code> of the output is generated.</p>
<p><strong>Using <code>--step 1 --out file</code></strong></p>
<p>For the <script type="math/tex">P</script> phenotypes, files <code>file_1.loco</code>,...,<code>file_P.loco</code> are output with the
per-chromosome LOCO predictions as rows of the files 
(following the order of the phenotypes in the phenotype file header). 
If option <code>--gz</code> was used, the files will be compressed in gzip format and have extension <code>.loco.gz</code>.</p>
<p>Genotyped individuals specified using option <code>--remove</code> are excluded from this file. 
Individuals with missing phenotype values kept in the analysis 
are included in the file and have their predictions set to missing.</p>
<p>The list of blup files needed for step 2 (association testing) is written to  <code>file_pred.list</code>.</p>
<p>If using <code>--print-prs</code>, files <code>file_1.prs</code>,...,<code>file_P.prs</code> will be written with the 
whole genome predictions (i.e. PRS) without using LOCO scheme (similar format as the .loco files).
The list of these files is written to <code>file_prs.list</code> and can be used in step 2 with <code>--pred</code> and 
specifying flag <code>--use-prs</code>. Note that as these are not obtained using a LOCO scheme, 
association tests could suffer from proximal contamination.</p>
<p>If using option <code>--write-null-firth</code>, the estimates for approximate Firth under the null will be written to files
<code>file_1.firth,...,file_P.firth</code> and the list of these files is written to <code>file_firth.list</code>. This can be
used in step 2 as <code>--use-null-firth file_firth.list</code>. Note that it assumes the same set of covariates are 
used in Step 1 and 2.</p>
<p><strong>Using<code>--step 2 --out file</code></strong> </p>
<p>By default, results are written in separate files for
each phenotype
<code>file_&lt;phenotype1_name&gt;.regenie,...,file_&lt;phenotypeP_name&gt;.regenie</code>.
Each file has one line per
SNP along with a header line.
If option <code>--gz</code> was used, the files will be compressed in gzip format and have extension <code>.regenie.gz</code>.</p>
<p>The entries of each row specify chromosome, position, ID, reference allele (allele 0), 
alternative allele (allele 1), frequency of the alternative allele, sample size and the test performed 
(additive/dominant/recessive).
With BGEN/PGEN files with dosages, the imputation INFO score is provided 
(IMPUTE info score for BGEN and Mach Rsq for PGEN).
Allele frequency, sample size and INFO score, if applicable, are computed using only
non-missing samples for each phenotype.</p>
<p>These are followed by the estimated effect sizes (for allele 1 on the original scale), standard errors, chi-square test statistics 
and <script type="math/tex">-\log_{10}</script> p-value. An additional column is included to specify if Firth/SPA corrections failed.</p>
<p>With option <code>--no-split</code>, the summary statistics for all traits are written to a single file <code>file.regenie</code>,
with the same format as above. Additionaly, an accompanying file with the trait names corresponding to Y1,Y2,... 
will be generated in ‘file.regenie.Ydict’. Note that allele frequency, sample size and INFO score are computed using
all analyzed samples.</p>
<p>If option <code>--write-samples</code> was used, IDs of samples used for each trait will be written in files
<code>file_&lt;phenotype1_name&gt;.regenie.ids,...,file_&lt;phenotypeP_name&gt;.regenie.ids</code> (tab separated, no header).</p>
<p>When using <code>--par-region</code>, the default boundaries used for the chrX PAR regions are:</p>
<ul>
<li>b36/hg18: 2709520 and 154584238</li>
<li>b37/hg19: 2699520 and 154931044</li>
<li>b38/hg38: 2781479 and 155701383</li>
</ul>
<h2 id="gene-based-testing">Gene-based testing</h2>
<p>Starting from version 3.0, Step 2 of <strong>regenie</strong> provides a complimentary set of gene-based test 
in addition to the burden testing functionality introduced in version 2.0.
More specifically, for a given set of variants (eg within a gene) which can be defined using functional annotations,
<strong>regenie</strong> can apply various set-based tests on the variants as well as collapse them into a single combined 'mask' genotype 
that can be tested for association just like a single variant. </p>
<h3 id="input_1">Input</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Argument</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--anno-file</code></td>
<td>FILE</td>
<td>Required</td>
<td>File with variant annotations for each set</td>
</tr>
<tr>
<td><code>--set-list</code></td>
<td>FILE</td>
<td>Required</td>
<td>File listing variant sets</td>
</tr>
<tr>
<td><code>--extract-sets</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Inclusion file that lists IDs of variant sets to keep</td>
</tr>
<tr>
<td><code>--exclude-sets</code></td>
<td>FILE</td>
<td>Optional</td>
<td>Exclusion file that lists IDs of variant sets to remove</td>
</tr>
<tr>
<td><code>--extract-setlist</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Comma-separated list of variant sets to keep</td>
</tr>
<tr>
<td><code>--exclude-setlist</code></td>
<td>STRING</td>
<td>Optional</td>
<td>Comma-separated list of variant sets to remove</td>
</tr>
<tr>
<td><code>--aaf-file</code></td>
<td>FILE</td>
<td>Optional</td>
<td>File with variant AAF to use when building masks (instead of AAF estimated from sample)</td>
</tr>
<tr>
<td><code>--mask-def</code></td>
<td>FILE</td>
<td>Required</td>
<td>File with mask definitions using the annotations defined in <code>--anno-file</code></td>
</tr>
</tbody>
</table>
<p>Note: multiple files can be specified for <code>--extract-sets/--exclude-sets</code> by using a comma-separated list.</p>
<h4 id="annotation-input-files">Annotation input files</h4>
<p>The following files are used to define variant sets and 
functional annotations which will be used to generate masks.</p>
<h5 id="annotation-file">Annotation file</h5>
<pre><code class="language-bash">1:55039839:T:C PCSK9 LoF
1:55039842:G:A PCSK9 missense
.
</code></pre>
<p>This file defines functional annotations for variants.
It is designed to accommodate for variants with 
separate annotations for different sets/genes.</p>
<p>Each line contains the variant name, the set/gene name and a single annotation category 
(space/tab separated). </p>
<p>Variants not in this file will be assigned to a default "NULL" category. A maximum of 63 annotation 
categories (+NULL category) is allowed.</p>
<p>For gene sets, tools you can use to obtain variant annotations per transcripts are 
<a href="https://pcingola.github.io/SnpEff/se_introduction/">snpEFF</a> or 
<a href="https://www.ensembl.org/info/docs/tools/vep/index.html">VEP</a>.
To obtain a single annotation per gene, you could choose the most deleterious
functional annotation across the gene transcripts or alternatively
use the canonical transcript (note that its definition can vary across software).</p>
<p>We have implemented an extended 4-column format of the annotation file which
also categorizes sets into domains (e.g. for gene sets, these would correspond to gene domains).</p>
<pre><code class="language-bash">1:55039839:T:C PCSK9 Prodomain LoF
1:55039842:G:A PCSK9 Prodomain missense
.
</code></pre>
<p>Masks will be generated for each domain 
(maximum of 8 per set/gene) in addition 
to a mask combining across all domains.
Variants can only be assigned to a single domain for each set/gene.</p>
<h5 id="set-list-file">Set list file</h5>
<p>This file lists variants within each set/gene to use when 
building masks. 
Each line contains the set/gene name followed by a chromosome and physical position for the set/gene,
then by a comma-separated list of variants included in the set/gene.</p>
<pre><code class="language-bash">A1BG 19  58346922  19:58346922:C:A,19:58346924:G:A,...
A1CF 10  50806630  10:50806630:A:G,10:50806630:A:AT,...
.
</code></pre>
<h5 id="set-inclusionexclusion-file-format">Set inclusion/exclusion file format</h5>
<p>The file must have a single column of set/gene names corresponding to those in the 
set list file.</p>
<pre><code class="language-bash">PIGP
ZBTB38
.
</code></pre>
<h5 id="aaf-file-optional">AAF file (optional)</h5>
<p>Both functional annotations and alternative allele frequency (AAF) cutoffs 
are used when building masks (e.g. only considering LoF
sites where AAF is below 1%). 
By default, the AAF for each variant is computed from the sample but
alternatively, the user can specify variant AAFs using this file.</p>
<p>Each line contains the variant name followed by its AAF 
(it should be for the ALT allele used in the genetic data input). 
AAF must be a numerical value (i.e. it cannot be '.').</p>
<pre><code class="language-bash">7:6187101:C:T 1.53918207864341e-05
7:6190395:C:A 2.19920388819247e-06
.
</code></pre>
<p>Since singleton variants cannot be identified from this file, they are determined by default
based on the input genetic data. To enforce which sites should be included in the singleton masks
(see <code>--set-singletons</code>), you can add a third column in the file with a binary indicator 
(1=singleton; 0=not singleton). So only variants which are specified as singletons will be 
considered for the singleton masks, regardless of whether they are singletons in the input genetic data.
Note that with this flag, singleton sites will be included in all masks (regardless of the AAF in file).</p>
<pre><code class="language-bash">7:6187101:C:T 1.53918207864341e-05 0
7:6190395:C:A 2.19920388819247e-06 1
.
</code></pre>
<h4 id="mask-definitions">Mask definitions</h4>
<h5 id="mask-file">Mask file</h5>
<p>This file specifies which annotation categories should be combined into masks. 
Each line contains a mask name followed by a comma-seperated list 
of categories included in the mask (i.e. union is taken over categories).</p>
<p>For example below, Mask1 uses only LoF variants and 
Mask2 uses LoF and missense annotated variants.</p>
<pre><code class="language-bash">Mask1 LoF
Mask2 LoF,missense
.
</code></pre>
<h5 id="aaf-cutoffs">AAF cutoffs</h5>
<p>Option <code>--aaf-bins</code> specifies the AAF upper bounds used to generate burden masks 
(<strong>AAF and not MAF [minor allele frequency] is used when deciding which variants go into a mask)</strong>.
By default, a mask based on singleton sites are always included.</p>
<p>For example, <code>--aaf-bins 0.01,0.05</code> will generate 3 burden masks for AAFs in 
[0,0.01], [0,0.05] and singletons.</p>
<h4 id="skatacat-tests">SKAT/ACAT tests</h4>
<p>The option <code>--vc-tests</code> is used to specify the gene-based tests to run. 
By default, these tests use all variants in each mask category. 
If you'd like to only include variants whose AAF is below a given threshold 
,e.g. only including rare variants, you can use <code>--vc-maxAAF</code>.</p>
<table>
<thead>
<tr>
<th align="left">Test</th>
<th align="left">Name in <strong>regenie</strong></th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">SKAT</td>
<td align="left">skat</td>
<td align="left">Variance component test</td>
</tr>
<tr>
<td align="left">SKATO</td>
<td align="left">skato</td>
<td align="left">Omnibus test combining features of SKAT and Burden</td>
</tr>
<tr>
<td align="left">SKATO-ACAT</td>
<td align="left">skato-acat</td>
<td align="left">Same as SKATO but using Cauchy combination method to maximize power across SKATO models</td>
</tr>
<tr>
<td align="left">ACATV</td>
<td align="left">acatv</td>
<td align="left">Test using Cauchy combination method to combine single-variant p-values</td>
</tr>
<tr>
<td align="left">ACATO</td>
<td align="left">acato</td>
<td align="left">Omnibus test combining features of ACATV, SKAT and Burden</td>
</tr>
<tr>
<td align="left">ACATO-FULL</td>
<td align="left">acato-full</td>
<td align="left">Same as ACATO but using the larger set of SKATO models used in the SKATO test</td>
</tr>
</tbody>
</table>
<p>For example, <code>--vc-tests skato,acato-full</code> will run SKATO and ACATO 
(both using the default grid of 8 <code>rho</code> values for the SKATO models) and 
the p-values for SKAT, SKATO, ACATV and ACATO will be output.</p>
<p>Ultra-rare variants (defined by default as MAC$\le$10, see <code>--vc-MACthr</code>) are collapsed into
a burden mask which is then included in the tests instead of the individual variants.</p>
<p>For additional details on the tests, <a href="../overview/#step-2-gene-based-testing">see here</a>.</p>
<h4 id="joint-test-for-burden-masks">Joint test for burden masks</h4>
<p>The following tests can be used to combine different burden masks 
generated using different annotation classes as well as AAF thresholds.</p>
<table>
<thead>
<tr>
<th align="left">Test</th>
<th align="center">Name in <strong>regenie</strong></th>
<th align="center">QT</th>
<th align="center">BT</th>
<th align="center">Robust to LD</th>
<th align="center">Assumes same effect direction</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">Minimum P-value</td>
<td align="center">minp</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\times$</td>
<td align="center">$\times$</td>
</tr>
<tr>
<td align="left">ACAT</td>
<td align="center">acat</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\times$</td>
</tr>
<tr>
<td align="left">SBAT</td>
<td align="center">sbat</td>
<td align="center">$\checkmark$</td>
<td align="center">$\times$</td>
<td align="center">$\checkmark$</td>
<td align="center">$\checkmark$</td>
</tr>
</tbody>
</table>
<p>The ACAT test combines the p-values of the individual burden masks using the Cauchy combination method 
(see ref. 14 <a href="../overview/#fn:14">here</a>).
The SBAT test is described into more detail <a href="../overview/#sparse-burden-association-test">here</a>.</p>
<p>If you only want to output the results for the joint tests (ignore the marginal tests), use <code>--joint-only</code>.</p>
<h4 id="lovolodo-schemes">LOVO/LODO schemes</h4>
<p>The leave-one-variant-out (LOVO) scheme takes all sites going into a mask,
and builds LOVO masks 
by leaving out one variant at a time from the full set of sites. 
The mask including all sites will also be computed.</p>
<p>The argument for <code>--mask-lovo</code> is a comma-separated list which 
consists of 
the set/gene name, 
the mask name, 
and the AAF cutoff (either 'singleton' or a double in (0,1)).</p>
<p>If using a 4-column annotation file, then <code>--mask-lovo</code> should have 
the gene name, 
the domain name,
the mask name, 
and the AAF cutoff.
So the LOVO masks will be generated for a specific gene domain.</p>
<p>The leave-one-domain-out (LODO) scheme (specified by <code>--mask-lodo</code>) 
takes all sites going into a mask and builds a LODO mask for each domain specified for the gene
by excluding all variants in the domain. 
The full mask including all sites will also be computed. 
The argument for <code>--mask-lodo</code> should have the gene name, the mask name and the AAF cutoff.</p>
<h4 id="writing-mask-files">Writing mask files</h4>
<p>Burden masks built in <strong>regenie</strong> can be written to PLINK bed format. 
If the input genetic data contains dosages, 
the masks dosages will be converted to hard-calls prior to being written to file 
and these hard-calls will be used for the association testing.</p>
<p>The PLINK bed file is written using 'ref-last' encoding (i.e. REF allele is 
listed last in the bim file).</p>
<p>Note that this cannot be used with the LOVO/LODO schemes.</p>
<h3 id="options_1">Options</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Argument</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--aaf-bins</code></td>
<td>FLOAT,...,FLOAT</td>
<td>Optional</td>
<td>comma-separated list of AAF upper bounds to use when building masks [default is a single cutoff of 1%]</td>
</tr>
<tr>
<td><code>--build-mask</code></td>
<td>STRING</td>
<td>Optional</td>
<td>build masks using the maximum number of ALT alleles across sites (<code>'max'</code>; the default), or the sum of ALT alleles (<code>'sum'</code>), or thresholding the sum to 2 (<code>'comphet'</code>)</td>
</tr>
<tr>
<td><code>--singleton-carrier</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to define singletons as variants with a single carrier in the sample (rather than alternative allele count=1)</td>
</tr>
<tr>
<td><code>--set-singletons</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to use 3rd column in AAF file to specify variants included in singleton masks</td>
</tr>
<tr>
<td><code>--write-mask</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>write mask to PLINK bed format <strong>(does not work when building masks with 'sum')</strong></td>
</tr>
<tr>
<td><code>--vc-tests</code></td>
<td>STRING</td>
<td>Optional</td>
<td>comma-separated list of SKAT/ACAT-type tests to run</td>
</tr>
<tr>
<td><code>--vc-maxAAF</code></td>
<td>FLOAT</td>
<td>Optional</td>
<td>AAF upper bound to use for SKAT/ACAT-type tests [default is 100%]</td>
</tr>
<tr>
<td><code>--skat-params</code></td>
<td>FLOAT,FLAT</td>
<td>Optional</td>
<td>a1,a2 values for the single variant weights computed from Beta(MAF,a1,a2) used in SKAT/ACAT-type tests [default is (1,25)]</td>
</tr>
<tr>
<td><code>--skato-rho</code></td>
<td>FLOAT,...,FLOAT</td>
<td>Optional</td>
<td>comma-separated list of $\rho$ values used for SKATO models</td>
</tr>
<tr>
<td><code>--vc-MACthr</code></td>
<td>FLOAT</td>
<td>Optional</td>
<td>MAC threshold below which to collapse variants in SKAT/ACAT-type tests [default is 10]</td>
</tr>
<tr>
<td><code>--joint</code></td>
<td>STRING</td>
<td>Optional</td>
<td>comma-separated list of joint tests to apply on the generated burden masks</td>
</tr>
<tr>
<td><code>--rgc-gene-p</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to compute the GENE_P test</td>
</tr>
<tr>
<td><code>--skip-test</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to skip computing association tests after building masks and writing them to file</td>
</tr>
<tr>
<td><code>--mask-lovo</code></td>
<td>STRING</td>
<td>Optional</td>
<td>to perform LOVO scheme</td>
</tr>
<tr>
<td><code>--lovo-snplist</code></td>
<td>FILE</td>
<td>Optional</td>
<td>File with list of variants for which to compute LOVO masks</td>
</tr>
<tr>
<td><code>--mask-lodo</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to perform LODO scheme</td>
</tr>
<tr>
<td><code>--write-mask-snplist</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to write list of variants that went into each mask to file</td>
</tr>
<tr>
<td><code>--check-burden-files</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to check the concordance between annotation, set list and mask files [see <a href="https://rgcgithub.github.io/regenie/options/#checking-input-files">below</a>]</td>
</tr>
<tr>
<td><code>--strict-check-burden</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to exit early if the annotation, set list and mask definition files dont agree [see <a href="https://rgcgithub.github.io/regenie/options/#checking-input-files">below</a>]</td>
</tr>
</tbody>
</table>
<p>Three rules can be used to build masks with <code>--build-mask</code> as shown in diagram below, 
where the last rule <code>comphet</code> applies a threshold of 2 to the mask from the <code>sum</code> rule.</p>
<p><img alt="MaskRules" src="../img/mask_rules.png" style="text-align:center;padding: 10px;width:60%;display: block;margin-left: auto;margin-right: auto" /></p>
<h3 id="output_1">Output</h3>
<p><strong>With <code>--out file</code></strong></p>
<p>Results are written in separate files for each phenotype
<code>file_&lt;phenotype1_name&gt;.regenie,...,file_&lt;phenotypeP_name&gt;.regenie</code> 
with the same output format mentioned <a href="https://rgcgithub.github.io/regenie/options/#output">above</a>.
Additionally, a header line is included (starting with <code>##</code>)
which contains mask definition information.</p>
<p>Masks will have name <code>&lt;set_name&gt;.&lt;mask_name&gt;.&lt;AAF_cutoff&gt;</code> with the 
chromosome and physical position having been defined in the set list file, 
and the reference allele being <code>ref</code>, and the alternate allele corresponding to 
<code>&lt;mask_name&gt;.&lt;AAF_cutoff&gt;</code>.
When using <code>--mask-lovo</code>, the mask name will be the same as above but have suffix
<code>_&lt;variant_name&gt;</code> to specify the variant which was excluded when building the mask.</p>
<p>With <code>--build-mask sum</code>, the reported mask AAF corresponds to the average 
AAF across sites included in the mask.</p>
<p>If using <code>--write-mask</code>, the masks will be saved to 
<code>file_masks.{bed,bim,fam}</code> and if using <code>--write-mask-snplist</code>, 
the list of variants included in each mask will be saved to <code>file_masks.snplist</code>. </p>
<p>When using <code>--rgc-gene-p</code>, it will apply the single p-value per gene GENE_P strategy 
using all masks (see <a href="../overview/#gene_p">here</a> for details).</p>
<h3 id="example-run">Example run</h3>
<p>Using Step 1 results from the <a href="https://rgcgithub.github.io/regenie/options/#getting-started">Step 1 command above</a>, we use the following command to build and test masks in Step 2</p>
<pre><code>./regenie \
  --step 2 \
  --bed example/example_3chr \
  --covarFile example/covariates.txt \
  --phenoFile example/phenotype_bin.txt \
  --bt \
  --remove example/fid_iid_to_remove.txt \
  --firth --approx \
  --pred fit_bin_out_pred.list \
  --anno-file example/example_3chr.annotations \
  --set-list example/example_3chr.setlist \
  --mask-def example/example_3chr.masks \
  --aaf-bins 0.1,0.05 \
  --write-mask \
  --bsize 200 \
  --out test_bin_out_firth
</code></pre>
<p>For each set, this will produce masks using 3 AAF cutoffs (singletons, 5% and 10% AAF). 
The masks are written to PLINK bed file (in <code>test_bin_out_firth_masks.{bed,bim,fam}</code>) 
and tested for association with each binary trait using Firth approximate test 
(summary stats in <code>test_bin_out_firth_&lt;phenotype_name&gt;.regenie</code>). 
Note that the test uses the whole genome regression LOCO PRS from Step 1 of <strong>regenie</strong> (specified by <code>--pred</code>).</p>
<h3 id="checking-input-files">Checking input files</h3>
<p>To assess the concordance between the input files for building masks, you can use  <code>--check-burden-files</code> which will generate a report in <code>file_masks_report.txt</code> containing:</p>
<ol>
<li>
<p>for each set, the list the variants in the set-list file which are unrecognized (not genotyped 
or not present in annotation file for the set)</p>
</li>
<li>
<p>for each mask, the list of annotations in the mask definition file which are not in the annotation file</p>
</li>
</ol>
<p>Additionally, you can use <code>--strict-check-burden</code> to
enforce full agreement between the three files 
(if not, program will terminate) :</p>
<ol>
<li>
<p>all genotyped variants in the set list file must be in the annotation file (for the corresponding set)</p>
</li>
<li>
<p>all annotations in the mask definition file must be present in the annotation file</p>
</li>
</ol>
<h2 id="interaction-testing">Interaction testing</h2>
<p>Starting from <strong>regenie</strong> v3.0, you can perform scans for interactions (either GxE or GxG). 
For GxE tests, the interacting variable should be part of the covariate file 
(if it is categorical, specify it in <code>--catCovarList</code>).
For GxG tests, the interacting variant can be part of the input genetic file 
or it can be present in an external file (see <code>--interaction-snp-file</code>)</p>
<h3 id="options_2">Options</h3>
<table>
<thead>
<tr>
<th>Option</th>
<th>Argument</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--interaction</code></td>
<td>STRING</td>
<td>Optional</td>
<td>to run GxE test specifying the interacting covariate (see below)</td>
</tr>
<tr>
<td><code>--interaction-snp</code></td>
<td>STRING</td>
<td>Optional</td>
<td>to run GxG test specifying the interacting variant (see below)</td>
</tr>
<tr>
<td><code>--interaction-file</code></td>
<td>FORMAT,FILE</td>
<td>Optional</td>
<td>external genotype file containing the interacting variant [FORMAT can be bed/bgen/pgen and FILE is the file name (bgen) or file prefix (bed/pgen)]</td>
</tr>
<tr>
<td><code>--interaction-file-sample</code></td>
<td>FILE</td>
<td>Optional</td>
<td>accompagnying sample file for BGEN format</td>
</tr>
<tr>
<td><code>--interaction-file-reffirst</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>use the first allele as the reference for BGEN or PLINK BED formats</td>
</tr>
<tr>
<td><code>--no-condtl</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to print out all the main effects from the interaction model (see Output section below)</td>
</tr>
<tr>
<td><code>--force-condtl</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>to include the interacting SNP as a covariate in the marginal test (see Output section below)</td>
</tr>
<tr>
<td><code>--rare-mac</code></td>
<td>FLOAT</td>
<td>Optional</td>
<td>minor allele count (MAC) threshold below which to use HLM method for QTs [default is 1000]</td>
</tr>
</tbody>
</table>
<p>For GxE tests where the interacting variable is categorical, you can specify the baseline level using <code>--interaction VARNAME[BASE_LEVEL]</code> (e.g. <code>--interaction BMI[&lt;25]</code>). Otherwise, the first value found in the covariate file will be used as the baseline level.</p>
<p>For GxG tests, the default coding for the interacting variant is additive. If you would like to use dominant/recessive/categorical coding, use <code>--interaction-snp SNP_NAME[dom/rec/cat]</code> (for example with dominant coding, <code>--interaction-snp SNPNAME[dom]</code> will allow for separate effects between carriers vs non-carriers of the interacting variant). The allowed values in the brackets are <code>add/dom/rec/cat</code>.</p>
<!---
force-ltco : to use a Leave-Two-Chromosome-Out (LTCO) scheme specifying the chromosome to remove from the LOCO PRS of Step 1
--->

<h3 id="output_2">Output</h3>
<p>The result files will contain multiple lines for the same variant corresponding to the
different null hypotheses being tested in the <a href="../overview/#step-2-interaction-testing">interaction model</a>
<script type="math/tex; mode=display">
g(\mu) = E\alpha + G\beta + (G\odot E)\gamma
</script>
</p>
<p>The suffix in the "TEST" column indicates which hypothesis is being tested:</p>
<ul>
<li>"ADD": marginal test where the interacting variable has <strong>not</strong> been added as a covariate $-$ this corresponds to $H_0: \beta = 0$ given $\alpha=\gamma = 0$<ul>
<li>this is only printed for GxG tests by default, or GxE using <code>--no-condtl</code></li>
</ul>
</li>
<li>"ADD-CONDTL": marginal test where the interacting variable has been added as a covariate (default for GxE tests) $-$ this corresponds to $H_0: \beta = 0$ given $\gamma = 0$<ul>
<li>this is only printed for GxE tests by default, or GxG using <code>--force-condtl</code></li>
</ul>
</li>
<li>"ADD-INT_VAR": test for the main effect of the interaction variable ("VAR" will be replaced by the name of the interacting variable) $-$ this corresponds to $H_0: \alpha = 0$<ul>
<li>this is only printed for GxG tests by default, or GxE using <code>--no-condtl</code></li>
<li>If the interacting variable is categorical, you will have separate lines for each level aside from the baseline level (e.g. "ADD-INT_BMI=25-30" and "ADD-INT_BMI=30+" where baseline level is "$&lt;$25")</li>
<li>will also output the effect of $E^2$ in "ADD-INT_VAR^2" if the trait is binary (see <a href="../overview/#step-2-interaction-testing">here</a>)</li>
</ul>
</li>
<li>"ADD-INT_SNP": test for main effect of tested SNP in the interaction model $-$ this corresponds to $H_0: \beta = 0$</li>
<li>"ADD-INT_SNPxVAR": test for interaction effect ("VAR" will be replaced by the name of the interacting variable) $-$ this corresponds to $H_0: \gamma = 0$<ul>
<li>If the interacting variable is categorical, you will have separate lines for each level aside from the baseline level (e.g. "ADD-INT_SNPxBMI=25-30" and "ADD-INT_SNPxBMI=30+" where baseline level is "$&lt;$25")<ul>
<li>With Firth correction, only the effect sizes for the interaction effect at each level will be reported and the LRT p-value will only be computed for the joint test on the interaction effects</li>
</ul>
</li>
</ul>
</li>
<li>"ADD-INT_$k$DF": joint test for main and interaction effect of tested variant ($k\ge2$ for categorical interacting variables) $-$ this corresponds to $H_0: \beta = \gamma = 0$</li>
</ul>
<h2 id="conditional-analyses">Conditional analyses</h2>
<p>Starting from <strong>regenie</strong> v3.0, you can specify genetic variants to add to the set of covariates when performing association testing. 
This works in both step 1 and 2, and can be used in conjunction with the gene-based tests or the interactiong testing feature.
The conditioning variants will automatically be ignored from the analysis.</p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Argument</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--condition-list</code></td>
<td>FILE</td>
<td>Required</td>
<td>file with list of variants to condition on</td>
</tr>
<tr>
<td><code>--condition-file</code></td>
<td>FORMAT,FILE</td>
<td>Optional</td>
<td>get conditioning variants from external file (same argument format as <code>--interaction-file</code>)</td>
</tr>
<tr>
<td><code>--condition-file-sample</code></td>
<td>FILE</td>
<td>Optional</td>
<td>accompagnying sample file for BGEN format</td>
</tr>
<tr>
<td><code>--max-condition-vars</code></td>
<td>INT</td>
<td>Optional</td>
<td>maximum number of conditioning variants [default is 10,000]</td>
</tr>
</tbody>
</table>
<h2 id="ld-computation">LD computation</h2>
<p>REGENIE can calculate LD between a group of variants on the same chromosome. </p>
<table>
<thead>
<tr>
<th>Option</th>
<th>Argument</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>--compute-corr</code></td>
<td>FLAG</td>
<td>Required</td>
<td>compute LD matrix and write to binary file</td>
</tr>
<tr>
<td><code>--output-corr-text</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>write Pearson correlations to text file</td>
</tr>
<tr>
<td><code>--forcein-vars</code></td>
<td>FLAG</td>
<td>Optional</td>
<td>retain all variants specified in <code>--extract</code> which absent from the genetic data in the LD matrix</td>
</tr>
<tr>
<td><code>--ld-extract</code></td>
<td>FILE</td>
<td>Optional</td>
<td>file listing single variants as well as burden masks to include in LD matrix (see below)</td>
</tr>
</tbody>
</table>
<p>Note that this can be quite memory intensive for large groups of variants (memory ~$8M^2$ bytes for $M$ variants).</p>
<h3 id="output_3">Output</h3>
<p><strong>Using<code>--step 2 --out file</code></strong> </p>
<p>By default, the LD matrix is stored in a binary compressed file <code>file.corr</code> and
the list of variants corresponding to the columns of the LD matrix are stored in <code>file.corr.snplist</code>.
The R script <a href="https://github.com/rgcgithub/regenie/blob/master/scripts/parseLD.r">scripts/parseLD.r</a> contains a function which returns the LD matrix, e.g. <code>get.corr.sq.matrix("file.corr")</code>.
Using <code>--output-corr-text</code> will write the Pearson correlations to a text file instead.</p>
<p>When using <code>--forcein-vars</code>, variants not present in the genetic data will be added as extra column/rows in the LD matrix. 
For these variants, the diagonal entries in the matrix will be set to 1 and the off-diagonal entries 0.</p>
<p><strong>Using<code>--ld-extract info.txt</code></strong> </p>
<p>This option is used compute LD between single variants and burden masks generated on-the-fly in REGENIE; it requires specifying <a href="#annotation-input-files">annotation files</a>.
The file <code>info.txt</code> should have three columns: variant type ('sv' or 'mask'), variant name, followed by the set (e.g. gene) name (this can be 'NA' for single variant). For example, it would look like:</p>
<pre><code>sv 1:1111:A:G NA 
sv 1:2222:C:T NA 
mask PCSK9.M1.0.01 PCSK9
.
</code></pre>
<p>Note that the set and mask names must match that used in REGENIE based on provided annotation files and allele frequency cutoffs. Variant/masks not present in the data will be kept in the LD matrix but will have the corresponding correlations set to 0.</p></div>
        
        
    </div>

    <footer class="col-md-12 text-center">
        
        <hr>
        <p>
        <small>REGENIE is licensed under the <a href='https://github.com/rgcgithub/regenie/blob/master/LICENSE'>MIT license</small><br>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
        </p>

        
        
    </footer>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../js/bootstrap-3.0.3.min.js"></script>
    
    <script>var base_url = ".."</script>
    
    <script src="../js/base.js"></script>
    <script src="../search/main.js"></script>

  <script type="text/javascript"
          src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML"></script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true},
jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
TeX: {
extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
equationNumbers: {
autoNumber: "AMS"
}
}
});
  </script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>


</html>
