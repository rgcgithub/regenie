<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="../img/favicon.ico">

    
    <title>Overview - regenie</title>
    

    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/v4-shims.css">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hack-font@3.3.0/build/web/hack.min.css">
    <link href='//rsms.me/inter/inter.css' rel='stylesheet' type='text/css'>
    <link href='//fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,700italic,400,300,600,700&subset=latin-ext,latin' rel='stylesheet' type='text/css'>
    <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
    <link href="../css/base.min.css" rel="stylesheet">
    <link href="../css/cinder.min.css" rel="stylesheet">

    

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
            <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
            <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
        <![endif]-->

    
    <script>
    (function(i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function() {
            (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
    })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

    ga('create', 'UA-166859683-2', 'auto');
    ga('send', 'pageview');
    </script>
    

     
</head>

<body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->

            <a class="navbar-brand" href="..">regenie</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="..">Home</a>
                    </li>
                
                
                
                    <li class="active">
                        <a href="./">Overview</a>
                    </li>
                
                
                
                    <li >
                        <a href="../install/">Install</a>
                    </li>
                
                
                
                    <li >
                        <a href="../options/">Documentation</a>
                    </li>
                
                
                
                    <li >
                        <a href="../performance/">Performance</a>
                    </li>
                
                
                
                    <li >
                        <a href="../recommendations/">UKBB Analysis</a>
                    </li>
                
                
                
                    <li >
                        <a href="../faq/">F.A.Q.</a>
                    </li>
                
                
                </ul>

            <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                            <i class="fas fa-search"></i> Search
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="..">
                            <i class="fas fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="next" href="../install/">
                            Next <i class="fas fa-arrow-right"></i>
                        </a>
                    </li>
            </ul>
        </div>
    </div>
</div>

    <div class="container">
        
        
        <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="first-level active"><a href="#overview">Overview</a></li>
            <li class="second-level"><a href="#step-1-whole-genome-model">Step 1 : Whole genome model</a></li>
                
                <li class="third-level"><a href="#ridge-regression-level-0">Ridge regression (level 0)</a></li>
                <li class="third-level"><a href="#cross-validation-level-1">Cross-validation (level 1)</a></li>
                <li class="third-level"><a href="#genetic-predictors-and-loco">Genetic predictors and LOCO</a></li>
                <li class="third-level"><a href="#multiple-phenotypes">Multiple phenotypes</a></li>
                <li class="third-level"><a href="#covariates">Covariates</a></li>
            <li class="second-level"><a href="#step-2-single-variant-association-testing">Step 2 : Single-variant association testing</a></li>
                
                <li class="third-level"><a href="#quantitative-traits">Quantitative traits</a></li>
                <li class="third-level"><a href="#binary-traits">Binary traits</a></li>
            <li class="second-level"><a href="#step-2-gene-based-testing">Step 2 : Gene-based testing</a></li>
                
                <li class="third-level"><a href="#burden-tests">Burden tests</a></li>
                <li class="third-level"><a href="#variance-component-tests">Variance component tests</a></li>
                <li class="third-level"><a href="#cauchy-combination-tests">Cauchy combination tests</a></li>
                <li class="third-level"><a href="#non-negative-least-square-test">Non-Negative Least Square test</a></li>
            <li class="second-level"><a href="#step-2-interaction-testing">Step 2 : Interaction testing</a></li>
                
            <li class="second-level"><a href="#missing-phenotype-data">Missing Phenotype data</a></li>
                
            <li class="second-level"><a href="#references">References</a></li>
                
    </ul>
</div></div>
        <div class="col-md-9" role="main">

<h2 id="overview">Overview</h2>
<p>This page provides an overview of the models and methods implemented in
<strong>regenie</strong>. A full description is given in our <a href="https://doi.org/10.1038/s41588-021-00870-7">paper</a>.</p>
<p><strong>regenie</strong> carries out genome-wide association tests for both
  quantitative and binary (case-control) phenotypes. It is designed to handle</p>
<ol>
<li>A large number of samples. For example, it is ideally suited to the
<a href="https://www.ukbiobank.ac.uk/">UK Biobank</a> dataset with 500,000 samples.</li>
<li>A combination of genetic data from a micro-array, imputation and
exome sequencing.</li>
<li>A large number of either quantitative traits (QTs) or binary
(case-control) traits (BTs)</li>
<li>Accounting for a set of covariates</li>
</ol>
<p>An overview of the <strong>regenie</strong> method is provided in the figure below.
Essentially, <strong>regenie</strong> is run in 2 steps:</p>
<ol>
<li>In the first step a subset of genetic markers are used to fit a
whole genome regression model that captures a good fraction of the
phenotype variance attributable to genetic effects.</li>
<li>In the second step, a larger set of genetic markers (e.g. imputed
markers) are tested for association with the phenotype <em>conditional
upon</em> the prediction from the regression model in Step 1, using a
leave one chromosome out (LOCO) scheme, that avoids proximal
contamination.</li>
</ol>
<p><img alt="Rflow" src="../img/regenie_overview2.png" style="text-align:center;padding: 10px;width:70%;border: 1px solid #ddd;display: block;margin-left: auto;margin-right: auto" />
<br></p>
<h3 id="step-1-whole-genome-model">Step 1 : Whole genome model</h3>
<p>In Step 1 a whole genome regression model is fit at a subset of the
total set of available genetic markers. These are typically a set of
several hundred thousand (<script type="math/tex">M</script>) common markers from a micro-array. </p>
<h4 id="ridge-regression-level-0">Ridge regression (level 0)</h4>
<p><strong>regenie</strong> reads in the <script type="math/tex">M</script> markers in blocks of <script type="math/tex">B</script> consecutive markers (<code>--bsize</code> option).</p>
<p>In each block, a set of ridge regression
  predictors are calculated for a small range of <script type="math/tex">J</script> shrinkage
  parameters <script type="math/tex"> \{\tau_1,\ldots, \tau_J\} </script> (using <code>--l0</code> option [default is 5]) .</p>
<p>For a block of SNPs in a <script type="math/tex">N\times B</script> matrix <script type="math/tex">X</script> and <script type="math/tex">N\times 1</script>
phenotype vector <script type="math/tex">Y</script> we calculate  <script type="math/tex">J</script>  predictors</p>
<p>
<script type="math/tex"> X\widehat{\beta}_1 \ldots, X\widehat{\beta}_J </script>
</p>
<p>where</p>
<p>
<script type="math/tex"> \widehat{\beta}_j = (X^TX+\tau_j I)^{-1}X^T Y</script>
</p>
<p>The idea behind using a range of shrinkage
  values is to capture the unknown number and size of truly
  associated genetic markers within each window. The ridge regression takes account of Linkage disequilibrium (LD) within each block.</p>
<p>These predictors are stored in place of the
  genetic markers in matrix <script type="math/tex">W</script>, providing a large reduction in data size. 
For example, if
  <script type="math/tex">M=500,000</script> and <script type="math/tex">B=1,000</script> and <script type="math/tex">J=5</script> shrinkage parameters are used, then the
  reduced dataset will have <script type="math/tex">JM/B=2,500</script> predictors.</p>
<p>Ridge regression is used in this step for both quantitative and binary
traits. </p>
<h4 id="cross-validation-level-1">Cross-validation (level 1)</h4>
<p>The predictors generated by the ridge regression step will all be
positively correlated with the phenotype. Thus, it is important to
account for that correlation when building a whole genome wide
regression model.</p>
<p>When analyzing a quantitative trait we use a second level of ridge
regression on the full set of <script type="math/tex">JM/B</script> predictors in <script type="math/tex">W</script>. This
approach is inspired by the method of stacked regressions<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>.</p>
<p>We fit the ridge regression for a range of shrinkage parameters (<code>--l1</code> option) and choose a single
best value using K-fold cross validation scheme. This assesses the
predictive performance of the model using held out sets of data, and aims to control
any over-fitting induced by using the first level of ridge regression
to derive the predictors.</p>
<p>In other words, we fit the model</p>
<p>
<script type="math/tex; mode=display">Y = W\alpha + \epsilon</script>
</p>
<p>where <script type="math/tex">\alpha</script> is estimated as <script type="math/tex">\widehat{\alpha} = (W^TW + \phi\,I)^{-1}W^TY</script>
and the parameter <script type="math/tex">\phi</script> is chosen
via K-fold cross-validation. </p>
<p>For binary traits, we use a logistic ridge regression model to combine
the predictors in <script type="math/tex">W</script>
</p>
<p>
<script type="math/tex; mode=display">\text{logit}(p) = \mu + W\alpha</script>
where <script type="math/tex">p</script> is the probability of being a case and <script type="math/tex">\mu</script> captures the effects of non-genetic covariates.</p>
<h4 id="genetic-predictors-and-loco">Genetic predictors and LOCO</h4>
<p>Once <script type="math/tex">\alpha</script> has been estimated we can construct the genetic prediction</p>
<p>
<script type="math/tex; mode=display">Z = W\widehat{\alpha}</script>
</p>
<p>Also, since each column of the matrix <script type="math/tex">W</script> will be associated with a
chromosome we can can also construct a genetic prediction ignoring any
one chromosome, by simply ignoring those columns when calculating the
prediction. This is known as the Leave One Chromosome Out (LOCO)
approach. These LOCO predictions are valuable at Step 2 of <strong>regenie</strong>
when each marker is tested for associated (see below).</p>
<p>For binary traits, it is the linear predictor in a logistic regression
model using LOCO that is saved,
and used as an offset when fitting logistic regression models to test
for association.</p>
<h4 id="multiple-phenotypes">Multiple phenotypes</h4>
<p>The dimension reduction step using ridge regression can be used very
efficiently to model multiple phenotypes at once. The ridge regression
equations for a block of SNPs in a <script type="math/tex">N\times B</script> matrix <script type="math/tex">X</script> and a single phenotype
in a <script type="math/tex">N\times 1</script> matrix <script type="math/tex">Y</script> take the form</p>
<p>
<script type="math/tex"> \widehat{\beta} = AY </script> where <script type="math/tex">A = (X^TX+\tau I)^{-1}X^T</script>
<strong>does not depend on <script type="math/tex">Y</script></strong></p>
<p>If instead <script type="math/tex">P</script> phenotypes are stored in columns of a <script type="math/tex">N\times P</script> matrix <script type="math/tex">Y</script>, then the matrix <script type="math/tex">A</script>
can be applied jointly to calculate the matrix of estimates <script type="math/tex">\widehat{\beta} = AY</script>,
and this can take advantage of parallel linear algebra
implementations in the Eigen matrix library.</p>
<h4 id="covariates">Covariates</h4>
<p>Covariates, such as age and sex and batch effect variables can be
included in the <strong>regenie</strong> model.</p>
<p>For quantitative traits, any covariates are regressed out of
phenotypes and genotypes before fitting the model.</p>
<p>For binary traits, we fit a null model with only covariates, and use
predictions from that model as an offset when fitting the logistic
regression model.</p>
<h3 id="step-2-single-variant-association-testing">Step 2 : Single-variant association testing</h3>
<p>In Step 2, a larger set of markers are tested for association with the
trait (or traits). As with Step 1, these markers are also read in
blocks of <script type="math/tex">B</script> markers, and tested for association. This avoids having
to have all markers stored in memory at once.</p>
<h4 id="quantitative-traits">Quantitative traits</h4>
<p>For quantitative traits, we use a linear regression model for
association testing.</p>
<ul>
<li>Covariates are regressed out of the phenotypes and genetic markers.</li>
<li>The LOCO predictions from Step 1 are removed from the phenotypes.</li>
<li>Linear regression is then used to test association of the residualized
phenotype and the genetic marker.</li>
<li>Parallel linear algebra operations in the Eigen library are used
  where possible.</li>
</ul>
<h4 id="binary-traits">Binary traits</h4>
<p>For binary traits, logistic regression score test is used to test association of
the phenotype and the genetic marker.</p>
<p>The logistic regression model includes the LOCO predictions from
  Step 1 <em>as an offset</em>. Covariates are included in the linear
  predictor in the usual way.</p>
<p>When the case-control ratio is imbalanced, standard association tests
don't control Type I error well at rare genetic markers. <strong>regenie</strong>
has two options to handle this</p>
<h5 id="firth-logistic-regression">Firth logistic regression</h5>
<p>Standard maximum likelihood estimates are generally biased. The Firth
correction<sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup>
removes much of the bias, and results in better calibrated test
statistics. The correction involves adding a penalty term to the
log-likelihood,</p>
<p>
<script type="math/tex; mode=display"> \widetilde{l}(\theta) = l(\theta) + {1 \over 2} \log I|\theta| </script>
</p>
<p>where the penalty term corresponds to the use of Jeffrey's Prior. 
This prior has the effect of shrinking the effect size towards zero.</p>
<p><strong>regenie</strong> uses a Firth correction when the p-value from the standard
  logistic regression test is below a threshold (default 0.05). 
It also includes a novel, accurate and fast approximate Firth correction which 
is ~60x faster than the exact Firth correction
(see the option <code>--firth</code>). </p>
<p>The p-value reported in <strong>regenie</strong> is based on a likelihood ratio test (LRT), and we use the Hessian of the log-likelihood without the penalty term to estimate the standard error (SE). 
This may cause an issue in meta-analyses with rare variants, as the effect size estimate and SE may not match with the LRT p-value. 
Hence, we added an option <code>--firth-se</code> to report a SE computed instead from the effect size estimate and the LRT p-value.</p>
<h5 id="saddle-point-approxiation-spa-test">Saddle point approxiation (SPA) test</h5>
<p>The SPA test approximates the null distribution of the test statistic
by approximating the cumulant generating function of the
test  statistic,  which  involves  all  of  the  higher  order
moments<sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup>$^,$<sup id="fnref:4"><a class="footnote-ref" href="#fn:4">4</a></sup>. This provides a better estimation of the tail probabilities compared to using
standard asymptotic theory which relies on the normal approximation and uses only the
first two moments of the dsitribution. A tail probability is obtained as </p>
<p>
<script type="math/tex; mode=display">  
\begin{align*}  
P&(T < t_{\text{obs}}) \approx
    \Phi(z), \text{ where,}\\
    z &= w + \frac{1}{w}\log{\frac{v}{w}}\\
    w &= \text{sign}(\delta^*)\sqrt{ 2 [ t_{\text{obs}}\, \delta^* - K(\delta^*)}],\,
    v = \delta^*\sqrt{K''(\delta^*)}
\end{align*}
</script>
</p>
<p>and <script type="math/tex">K(\delta)</script> is the cumulant generating function of the test statistic and <script type="math/tex">\delta^*</script> 
is obtained by using a root-finding algorithm for <script type="math/tex">K'(\delta)=t_{\text{obs}}</script>. As this approximation
has been found not to work very well for ultra-rare variants, a minimum minor 
allele count (MAC) is used to filter out these variants before testing (option <code>--minMAC</code>).</p>
<h3 id="step-2-gene-based-testing">Step 2 : Gene-based testing</h3>
<p>Instead of performing single-variant association tests, multiple variants can be aggregated
in a given region, such as a gene, using the following model</p>
<p>
<script type="math/tex; mode=display">g(\mu) = w_1G_1\beta_1 + \dots + w_mG_m\beta_m</script>
</p>
<p>where <script type="math/tex">G_i</script>'s represent the single variants included in the test,
<script type="math/tex">w_i</script>'s and <script type="math/tex">\beta_i</script>'s are weights and effect sizes, respectively, for each variant,
and <script type="math/tex">g(.)</script> is a link function for the phenotypic mean <script type="math/tex">\mu</script>. 
We also denote by <script type="math/tex">S_i</script> the score statistics obtained from the 
<a href="#step-2-single-variant-association-testing">single-variant tests</a>.
This can be especially helpful when testing rare variants as single-variant 
tests usually have lower power performance.</p>
<p>To avoid inflation in the gene-based tests due to rare variants as well as reduce computation time, we have implemented the collapsing approach
proposed in SAIGE-GENE+<sup id="fnref:5"><a class="footnote-ref" href="#fn:5">5</a></sup>, where ultra-rare variants are aggregated into a mask.
For highly imbalanced binary traits, SPA/Firth correction can be used to calibrate the test statistics in the
gene-based tests as proposed in Zhao et al. (2020)<sup id="fnref:6"><a class="footnote-ref" href="#fn:6">6</a></sup> using <code>--firth/--spa</code>. </p>
<h4 id="burden-tests">Burden tests</h4>
<p>Burden tests, as defined in Lee et al. (2014)<sup id="fnref:7"><a class="footnote-ref" href="#fn:7">7</a></sup>, assume <script type="math/tex">\beta_i=\beta\; \forall i</script>, where <script type="math/tex">\beta</script> is a fixed coefficient, which then leads to the test statistic
<script type="math/tex; mode=display">Q_{BURDEN} = \left(\sum_i w_iS_i\right)^2</script>
These tests collapse variants into a single variable which is then tested for association with the phenotype. Hence, they are more powerful when variants have effects in the same direction and of similar magnitude. 
In <strong>regenie</strong>, multiple options are available to aggregate variants together into a burden mask beyond the linear combination above (<a href="../options/#options_1">see here</a>). 
For example, the burden tests that were employed in Backman et al. (2021)<sup id="fnref:8"><a class="footnote-ref" href="#fn:8">8</a></sup>
use the default strategy in <strong>regenie</strong> of collapsing variants by taking
the maximum number of rare alleles across the sites.</p>
<h4 id="variance-component-tests">Variance component tests</h4>
<p>Unlike burden tests, SKAT<sup id="fnref:9"><a class="footnote-ref" href="#fn:9">9</a></sup> assume the effect sizes $\beta_i$ come from an arbitrary
distribution with mean 0 and variance $\tau^2$ which leads to the test statistic
<script type="math/tex; mode=display">Q_{SKAT} = \sum_i w_i^2S_i^2</script>
Hence, SKAT can remain powerful when variant effects are in opposite directions.</p>
<p>The omnibus test SKATO<sup id="fnref:10"><a class="footnote-ref" href="#fn:10">10</a></sup> combines the SKAT and burden tests as 
<script type="math/tex; mode=display">Q_{SKATO} = \rho Q_{BURDEN} + (1-\rho) Q_{SKAT}</script>
So setting $\rho=0$ corresponds to SKAT and $\rho=1$ to the burden test.
In practice, the parameter $\rho$ is chosen to maximize the power 
[<strong>regenie</strong> uses a default grid of 8 values {$0, 0.1^2, 0.2^2, 0.3^2, 0.4^2, 0.5^2, 0.5, 1$}
and set the weights $w_i = Beta(MAF_i,1,25)$].</p>
<p>To obtain the p-value from a linear combination of chi-squared variables, <strong>regenie</strong> uses Davies' exact method<sup id="fnref:11"><a class="footnote-ref" href="#fn:11">11</a></sup> by default.
Following Wu et al (2016)<sup id="fnref:12"><a class="footnote-ref" href="#fn:12">12</a></sup>, <strong>regenie</strong> uses Kuonen's saddlepoint approximation method<sup id="fnref:13"><a class="footnote-ref" href="#fn:13">13</a></sup> when the Davies' p-value
is below 1e-5 and if that fails, it uses Davies' method with more stringent convergence parameters (lim=1e5,acc=1e-9). </p>
<p>The original SKATO method uses numerical integration when maximizing power across the 
various SKATO models that use different values for $\rho$. 
We also implement a modification of SKATO, named SKATO-ACAT, 
which instead uses the Cauchy combination method<sup id="fnref:14"><a class="footnote-ref" href="#fn:14">14</a></sup> 
to combine the p-values from the different SKATO models.</p>
<h4 id="cauchy-combination-tests">Cauchy combination tests</h4>
<p>The ACATV<sup id="fnref:15"><a class="footnote-ref" href="#fn:15">15</a></sup> test uses the Cauchy combination method to combine single variant p-values $p_i$ as
<script type="math/tex; mode=display">Q_{ACATV} = \sum_i \widetilde{w}_i^2\tan{\{\pi(0.5 - p_i)\}}</script>
where we set $\widetilde{w}_i = w_i \sqrt{MAF(1-MAF)}$. 
This test is highly computationally tractable and is robust to correlation between the single variant tests.</p>
<p>The omnibus test ACATO<sup id="fnref2:15"><a class="footnote-ref" href="#fn:15">15</a></sup> combines ACATV with the SKAT and burden tests as 
<script type="math/tex; mode=display">
Q_{ACATO} = 
\frac{1}{3}\tan{\{\pi(0.5 - p_{ACATV})\}}+
\frac{1}{3}\tan{\{\pi(0.5 - p_{Burden})\}}+
\frac{1}{3}\tan{\{\pi(0.5 - p_{SKAT})\}}
</script>
</p>
<p>where unlike the original ACATO test, we only use one set of the weights $w_i$.
Alternatively, we augment the test to include an extended set of SKATO models beyond SKAT and Burden
(which correspond to $\rho$ of 0 and 1 in SKATO respectively) and use the default SKATO grid of 8 values for $\rho$.</p>
<h4 id="non-negative-least-square-test">Non-Negative Least Square test</h4>
<p><strong>regenie</strong> can generate burden masks which are obtained by aggregating single variants
using various annotation classes as well as allele frequency
thresholds. The Non-Negative Least Square (NNLS) test<sup id="fnref:16"><a class="footnote-ref" href="#fn:16">16</a></sup> combines these burden masks
in a joint model imposing constraints of same direction of effects
<script type="math/tex; mode=display">
\mu = \sum_{\text{mask }i} M_i\gamma_i
</script>
where $M_i$ represent a burden mask and we solve
<script type="math/tex; mode=display">
\underset{\boldsymbol\gamma}{\min} || Y - \sum_i M_i\gamma_i||^2 
\text{ subject to } \gamma_i \ge 0 \text{ for all } i
</script>
</p>
<p>The NNLS method tests the hypothesis $H_0: \gamma_i=0$ for all $i$ vs.
$H_1: \gamma_i &gt; 0$ for some $i$.
By using this joint model, the NNLS test accounts for the correlation structure between the burden masks 
and with the non-negative constraints,
it can lead to boost in power performance when multiple burden masks are causal and have concordant effects.
This test has the nice property that it combines 
model selection of the masks (via the sparsity induced by the non-negative assumption) 
with model inference (it is well calibrated and powerful).</p>
<h3 id="step-2-interaction-testing">Step 2 : Interaction testing</h3>
<p>The GxE tests are of the form
<script type="math/tex; mode=display">
g(\mu) = E\alpha + G\beta + (G\odot E)\gamma
</script>
where $E$ is an environmental risk factor and $G$ is a marker of interest,
and $\odot$ represents the Haddamard (entry-wise) product of the two.
The last term in the model allows for the variant to have different effects across values of the risk factor. 
<em>Note: if $E$ is categorical, we use a dummy variable for each level of $E$ in the model above.</em></p>
<p>We can look at the following hypotheses:</p>
<ol>
<li>$H_0: \beta = 0$ given $\gamma = 0$, which is a marginal test for the SNP</li>
<li>$H_0: \beta = 0$, which is a test for the main effect of the SNP in the full model</li>
<li>$H_0: \gamma = 0$, which is a test for interaction</li>
<li>$H_0: \beta = \gamma = 0$, which tests both main and interaction effects for the SNP</li>
</ol>
<p>Misspecification of the model above, 
such as in the presence of heteroskedasticity, or 
the presence of high case-control imbalance can lead to inflation in the tests.
Robust (sandwich) standard error (SE) estimators<sup id="fnref:17"><a class="footnote-ref" href="#fn:17">17</a></sup> can be used to adress model misspecification however, 
they can suffer from inflation when testing rare variants
or in the presence of high case-control imbalance<sup id="fnref:18"><a class="footnote-ref" href="#fn:18">18</a></sup>$^,$<sup id="fnref:19"><a class="footnote-ref" href="#fn:19">19</a></sup>.</p>
<p>In <strong>regenie</strong>, we use a hybrid approach which combines:</p>
<ul>
<li>Wald test with sandwich estimators</li>
<li>Wald test with heteroskedastic linear models (for quantitative traits)</li>
<li>LRT with penalized Firth regression (for binary traits)</li>
</ul>
<p>For quantitative traits,
we use the sandwich estimators HC3 to perform a Wald test for variants whose minor allele count (MAC) is above 1000 (see <code>--rare-mac</code>). 
For the remaining variants, we fit a heteroskedastic linear model (HLM)<sup id="fnref:20"><a class="footnote-ref" href="#fn:20">20</a></sup>
<script type="math/tex; mode=display">
Y = E\alpha + E^2\zeta + G\beta + (G\odot E)\gamma + \epsilon
</script>
</p>
<p>where we assume $\epsilon \sim N(0, D)$ where $D$ is a diagonal matrix with entries $\sigma^2\exp{(1 + E\theta_1 + E^2\theta_2)}$.
This formulation allows for the phenotypic variance to also depend on the risk factor $E$.
By incorporating both the linear and quadratic effect of $E$ in the mean and variance of $Y$, 
this model provides robustness to heteroskedasticity 
(<em>Note: the $E^2$ terms are only added when $E$ is quantitative</em>). 
Wald tests are then performed for the null hypotheses listed above.</p>
<p>For binary traits, we consider the following interaction model
<script type="math/tex; mode=display">
\text{logit}(\mu) = E\alpha + E^2\zeta + G\beta + (G\odot E)\gamma
</script>
where we also include a non-linear effect for $E$ (not if categorical).
The sandwich estimator HC3 is used in a Wald test for variants whose MAC is above 1000 (see <code>--rare-mac</code>) otherwise the model-based standard errors are used.
When Firth is specified, we only apply the Firth correction using LRT if the p-value for the interaction term $\gamma$ from the Wald test is below a specified threshold (see <code>--pThresh</code>). So the added $E^2$ term as well as the use of the Firth penalty 
help with case-control imbalance and model misspecification for the effect of $E$ on the phenotype. </p>
<h3 id="missing-phenotype-data">Missing Phenotype data</h3>
<p>With QTs, missing values are mean-imputed in Step 1 and they are 
dropped when testing each phenotype in Step 2 (unless using <code>--force-impute</code>).</p>
<p>With BTs, missing values are mean-imputed in Step 1 when fitting the
level 0 linear ridge regression and they are dropped when fitting the
level 1 logistic ridge regression for each trait. In Step 2, missing 
values are dropped when testing each trait.</p>
<p>To remove all samples that have missing values at <strong>any</strong> of the <script type="math/tex">P</script>
phenotypes from the analysis, use option <code>--strict</code> in step 1 and 2. 
This can also be used when analyzing a single trait to only keep individuals with 
complete data by setting the phenotype values of individuals to remove to NA.</p>
<p>Note: imputation is only applied to phenotypes; covariates are not allowed to have missing data.</p>
<h3 id="references">References</h3>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>Breiman, L. Stacked regressions. <em>Machine learning</em> <strong>24</strong>, 49--64 (1996).&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn:2">
<p>Firth, D. Bias reduction of maximum likelihood estimates. <em>Biometrika</em> <strong>80</strong>, 27--38 (1993).&#160;<a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn:3">
<p>Butler, R. W. <em>Saddlepoint approximations with applications</em>. (Cambridge University Press, 2007).&#160;<a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn:4">
<p>Dey, R., Schmidt, E. M., Abecasis, G. R. &amp; Lee, S. A fast and accurate algorithm to test for binary phenotypes and its application to PheWAS. <em>The American Journal of Human Genetics</em> <strong>101</strong>, 37--49 (2017).&#160;<a class="footnote-backref" href="#fnref:4" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
<li id="fn:5">
<p>Zhou, W. <em>et al.</em> Set-based rare variant association tests for biobank scale sequencing data sets. <em>medRxiv</em> (2021).&#160;<a class="footnote-backref" href="#fnref:5" title="Jump back to footnote 5 in the text">&#8617;</a></p>
</li>
<li id="fn:6">
<p>Zhao, Z. <em>et al.</em> UK biobank whole-exome sequence binary phenome analysis with robust region-based rare-variant test. <em>Am J Hum Genet</em> <strong>106</strong>, 3--12 (2020).&#160;<a class="footnote-backref" href="#fnref:6" title="Jump back to footnote 6 in the text">&#8617;</a></p>
</li>
<li id="fn:7">
<p>Lee, S., Abecasis, G. R., Boehnke, M. &amp; Lin, X. Rare-variant association analysis: Study designs and statistical tests. <em>Am J Hum Genet</em> <strong>95</strong>, 5--23 (2014).&#160;<a class="footnote-backref" href="#fnref:7" title="Jump back to footnote 7 in the text">&#8617;</a></p>
</li>
<li id="fn:8">
<p>Backman, J. D. <em>et al.</em> Exome sequencing and analysis of 454,787 UK biobank participants. <em>Nature</em> <strong>599</strong>, 628--634 (2021).&#160;<a class="footnote-backref" href="#fnref:8" title="Jump back to footnote 8 in the text">&#8617;</a></p>
</li>
<li id="fn:9">
<p>Wu, M. C. <em>et al.</em> Rare-variant association testing for sequencing data with the sequence kernel association test. <em>Am J Hum Genet</em> <strong>89</strong>, 82--93 (2011).&#160;<a class="footnote-backref" href="#fnref:9" title="Jump back to footnote 9 in the text">&#8617;</a></p>
</li>
<li id="fn:10">
<p>Lee, S., Wu, M. C. &amp; Lin, X. Optimal tests for rare variant effects in sequencing association studies. <em>Biostatistics</em> <strong>13</strong>, 762--75 (2012).&#160;<a class="footnote-backref" href="#fnref:10" title="Jump back to footnote 10 in the text">&#8617;</a></p>
</li>
<li id="fn:11">
<p>Davies, R. B. Algorithm AS 155: The distribution of a linear combination of Ï‡ 2 random variables. <em>Applied Statistics</em> <strong>29</strong>, 323--333 (1980).&#160;<a class="footnote-backref" href="#fnref:11" title="Jump back to footnote 11 in the text">&#8617;</a></p>
</li>
<li id="fn:12">
<p>Wu, B., Guan, W. &amp; Pankow, J. S. On efficient and accurate calculation of significance p-values for sequence kernel association testing of variant set. <em>Ann Hum Genet</em> <strong>80</strong>, 123--35 (2016).&#160;<a class="footnote-backref" href="#fnref:12" title="Jump back to footnote 12 in the text">&#8617;</a></p>
</li>
<li id="fn:13">
<p>Kuonen, D. Miscellanea. Saddlepoint approximations for distributions of quadratic forms in normal variables. <em>Biometrika</em> <strong>86</strong>, 929--935 (1999).&#160;<a class="footnote-backref" href="#fnref:13" title="Jump back to footnote 13 in the text">&#8617;</a></p>
</li>
<li id="fn:14">
<p>Liu, Y. &amp; Xie, J. Cauchy combination test: A powerful test with analytic p-value calculation under arbitrary dependency structures. <em>J Am Stat Assoc</em> <strong>115</strong>, 393--402 (2020).&#160;<a class="footnote-backref" href="#fnref:14" title="Jump back to footnote 14 in the text">&#8617;</a></p>
</li>
<li id="fn:15">
<p>Liu, Y. <em>et al.</em> ACAT: A fast and powerful p value combination method for rare-variant analysis in sequencing studies. <em>Am J Hum Genet</em> <strong>104</strong>, 410--421 (2019).&#160;<a class="footnote-backref" href="#fnref:15" title="Jump back to footnote 15 in the text">&#8617;</a><a class="footnote-backref" href="#fnref2:15" title="Jump back to footnote 15 in the text">&#8617;</a></p>
</li>
<li id="fn:16">
<p>Ziyatdinov, A., Barber, M. &amp; Marchini, J. Pooling information across burden tests in the UK biobank exome sequencing study. <em>ASHG Conference</em> (2020).&#160;<a class="footnote-backref" href="#fnref:16" title="Jump back to footnote 16 in the text">&#8617;</a></p>
</li>
<li id="fn:17">
<p>MacKinnon, J. G. &amp; White, H. Some heteroskedasticity-consistent covariance matrix estimators with improved finite sample properties. <em>Journal of Econometrics</em> <strong>29</strong>, 305--325 (1985).&#160;<a class="footnote-backref" href="#fnref:17" title="Jump back to footnote 17 in the text">&#8617;</a></p>
</li>
<li id="fn:18">
<p>Tchetgen Tchetgen, E. J. &amp; Kraft, P. On the robustness of tests of genetic associations incorporating gene-environment interaction when the environmental exposure is misspecified. <em>Epidemiology</em> <strong>22</strong>, 257--61 (2011).&#160;<a class="footnote-backref" href="#fnref:18" title="Jump back to footnote 18 in the text">&#8617;</a></p>
</li>
<li id="fn:19">
<p>Voorman, A., Lumley, T., McKnight, B. &amp; Rice, K. Behavior of QQ-plots and genomic control in studies of gene-environment interaction. <em>PLoS One</em> <strong>6</strong>, (2011).&#160;<a class="footnote-backref" href="#fnref:19" title="Jump back to footnote 19 in the text">&#8617;</a></p>
</li>
<li id="fn:20">
<p>Young, A. I., Wauthier, F. L. &amp; Donnelly, P. Identifying loci affecting trait variability and detecting interactions in genome-wide association studies. <em>Nat Genet</em> <strong>50</strong>, 1608--1614 (2018).&#160;<a class="footnote-backref" href="#fnref:20" title="Jump back to footnote 20 in the text">&#8617;</a></p>
</li>
</ol>
</div></div>
        
        
    </div>

    <footer class="col-md-12 text-center">
        
        <hr>
        <p>
        <small>REGENIE is licensed under the <a href='https://github.com/rgcgithub/regenie/blob/master/LICENSE'>MIT license</small><br>
        
        <small>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</small>
        </p>

        
        
    </footer>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <script src="../js/bootstrap-3.0.3.min.js"></script>
    
    <script>var base_url = ".."</script>
    
    <script src="../js/base.js"></script>
    <script src="../search/main.js"></script>

  <script type="text/javascript"
          src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML"></script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
tex2jax: {
inlineMath: [['$','$'], ['\\(','\\)']],
processEscapes: true},
jax: ["input/TeX","input/MathML","input/AsciiMath","output/CommonHTML"],
extensions: ["tex2jax.js","mml2jax.js","asciimath2jax.js","MathMenu.js","MathZoom.js","AssistiveMML.js", "[Contrib]/a11y/accessibility-menu.js"],
TeX: {
extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"],
equationNumbers: {
autoNumber: "AMS"
}
}
});
  </script>

    <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal">
                    <span aria-hidden="true">&times;</span>
                    <span class="sr-only">Close</span>
                </button>
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>
    </body>


</html>
